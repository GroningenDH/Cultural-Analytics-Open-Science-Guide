{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping â€” Part 2 â€” Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to introduce how to scrape multiple web pages from the internet with the Python libraries requests and BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Demonstration of Image Scraping â€” NYT Front Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Requests and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we're going to use the `requests` library and the `BeautifulSoup` library to scrape data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get HTML Data and Extract Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The New York Times* Front Page: https://nytimes.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're going to request the url for *The New York Times* front page, extract the text of the web page, then transform it into BeautifulSoup document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://nytimes.com\")\n",
    "html_string = response.text\n",
    "document = BeautifulSoup(html_string, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we search through the HTML code to find all the `<img>` tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document.find_all('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display these images in our Jupyter notebook, we're going to import the Python modules `Markdown` and `display`, which allow us to transform code output into Markdown and thus display the images in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Loop through all the images on the NYT front page\n",
    "for image in document.find_all('img'):\n",
    "    \n",
    "    # Convert the image tag to a string\n",
    "    image_string = str(image)\n",
    "    \n",
    "    # Transform the tag to Markdown and then display it as Markdown\n",
    "    display(Markdown(image_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Demonstration of Image Scraping â€” Bill Gates's LinkedIn Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.linkedin.com/in/williamhgates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.linkedin.com/in/williamhgates/\")\n",
    "html_string = response.text\n",
    "document = BeautifulSoup(html_string, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Loop through all the images on the NYT front page\n",
    "for image in document.find_all('img'):\n",
    "    # Convert the image tag to a string\n",
    "    image_string = str(image)\n",
    "    # Transform the tag to Markdown and then display it as Markdown\n",
    "    display(Markdown(image_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going wrong here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Multiple Web Pages At a Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we figured out how to scrape the lyrics for a single Missy Elliott song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://genius.com/Missy-elliott-work-it-lyrics\")\n",
    "html_string = response.text\n",
    "document = BeautifulSoup(html_string, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document.find('p').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how can we scrape lyrics for multiple Missy Elliott songs at a time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Out the Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to do is figure out how to progammatically generate the correct Genius web page URL for each song we're interested in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f\"https://genius.com/Missy-elliott-{formatted_song}-lyrics\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_titles = ['Work It', 'WTF (Where They From)', 'The Rain (Supa Dupa Fly)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "for song in song_titles:\n",
    "    formatted_song = ?????\n",
    "    response = requests.get(f\"https://genius.com/Missy-elliott-{formatted_song}-lyrics\")\n",
    "    html_string = response.text\n",
    "    document = BeautifulSoup(html_string, \"html.parser\")\n",
    "    document.find('p').text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the Genius web pages for each of these songs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://genius.com/Missy-elliott-work-it-lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://genius.com/Missy-elliott-the-rain-supa-dupa-fly-lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://genius.com/Missy-elliott-wtf-where-they-from-lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Song Titles Fit Pattern â€” Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function called `format_song()` that will take in a song title and then return the song title correctly formatted for its Genius web page.\n",
    "\n",
    "For example, the song `WTF (Where They From)` needs to be converted to `wtf-where-they-from`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You will need to use [string methods](https://info1350.github.io/Intro-CA-SP21/02-Python/06-String-Methods.html#id1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_song(song):\n",
    "    #Your Code Here ðŸ‘‡\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return formatted_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of your function on these two song titles to make sure it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wtf-where-they-from'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_song('WTF (Where They From)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work-it'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_song('Work It')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_titles = ['Work It', 'WTF (Where They From)', 'The Rain (Supa Dupa Fly)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your `format_song()` function to create the variable `formatted_song`, which will allow the code below to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in song_titles:\n",
    "    formatted_song = ???? #Use your format_song() function here\n",
    "    response = requests.get(f\"https://genius.com/Missy-elliott-{formatted_song}-lyrics\")\n",
    "    html_string = response.text\n",
    "    document = BeautifulSoup(html_string, \"html.parser\")\n",
    "    lyrics = document.find('p').text\n",
    "    print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Lyrics to a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_titles = ['Work It', 'WTF (Where They From)', 'The Rain (Supa Dupa Fly)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are writing the lyrics to a text file rather than printing them out.\n",
    "\n",
    "Again, use your `format_song()` function to create the variable `formatted_song`, which will allow the code below to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Missy-Elliott-Lyrics.txt', mode='w') as file_object:\n",
    "    \n",
    "    for song in song_titles:\n",
    "        formatted_song = format_song(song)  #Use your format_song() function here\n",
    "        response = requests.get(f\"https://genius.com/Missy-elliott-{formatted_song}-lyrics\")\n",
    "        html_string = response.text\n",
    "        document = BeautifulSoup(html_string, \"html.parser\")\n",
    "        lyrics = document.find('p').text\n",
    "        \n",
    "        file_object.write(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Top Words From File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to find out the most frequent words in Missy Elliott's lyrics, we could use the word counter code that we've used in previous lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp']\n",
    "\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "def get_top_words(full_text, number_of_words=20):\n",
    "    all_the_words = split_into_words(full_text)\n",
    "    meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "    meaningful_words_tally = Counter(meaningful_words)\n",
    "    most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_words)\n",
    "    return most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the file that we created and get the top words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missy_lyrics = open('Missy-Elliott-Lyrics.txt').read()\n",
    "get_top_words(missy_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What patterns do you notice about the top 20 words from these Missy Elliott songs?\n",
    "Feel free to open the text file in the file browser at the left and inspect the lyrics manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: If You Wanted to Change the Artist..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = 'Bts'\n",
    "song_titles = ['Dynamite', 'Euphoria', 'Fake Love']\n",
    "\n",
    "for song in song_titles:\n",
    "    formatted_song = ???? #Use your format_song() function here\n",
    "    response = requests.get(f\"https://genius.com/{artist}-{formatted_song}-lyrics\")\n",
    "    html_string = response.text\n",
    "    document = BeautifulSoup(html_string, \"html.parser\")\n",
    "    lyrics = document.find('p').text\n",
    "    print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do you think scholars should use web scraping in their research? Why or why not?\n",
    "* How would you feel if you found out that one of your social media posts had been included in an academic article without your knowledge?\n",
    "* What are some strategies that you think scholars might use to do web scraping in an ethical way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
